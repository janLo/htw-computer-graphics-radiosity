\documentclass[final,a4paper,11pt,notitlepage,halfparskip]{scrreprt}

\usepackage[german,ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[babel,german=quotes]{csquotes}
%\usepackage{fancybox}
%\usepackage{color}
\usepackage{xcolor}
\usepackage{hyperref}
%\usepackage{floatflt}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
%\usepackage{listings}

\setkomafont{caption}{\footnotesize\linespread{1}\selectfont}
\setlength{\abovecaptionskip}{-0.1cm}
\addto\captionsngerman{\renewcommand\figurename{Abb.}}

\subject{Beleg Computergraphik I}
\title{Komplexaufgabe\\
Beleuchtungsverfahren}
\author{Jan Losinski\\
\small{Mat. Nr. 25517}\\
\small{g08s29}}

\begin{document}

\maketitle

\tableofcontents

\chapter{Aufgabe}
\section{Wortlaut}
\subsection{Aufgabe}
Es ist ein System zu entwickeln, das die Beleuchtungsrechnung für eine dreidimensionale
Szene auf der Basis von C und OpenGL unter Umgehung der OpenGL-
Schattierungsfunktionen selbst durchführt.

\subsection{Durchführung}
Die Arbeiten können über das Semester verteilt parallel zu den übrigen Praktikumsaufgaben
ausgeführt werden und sind zum Ende der Lehrveranstaltungszeit abzuschließen. Zur
Implementation können alle in C und OpenGL angebotenen Mittel eingesetzt werden mit
Ausnahme der Oberflächen, Lichtquellen und Materialien einbeziehenden automatischen
Schattierungsfunktionen.

\subsection{Schwerpunkte}
Folgende grundlegende Aufgaben sind obligatorisch zu lösen:

\begin{enumerate}
    \item Definition eines darzustellenden ebenen Objektes im Raum
    \item Definition einer Lichtquelle im Raum
    \item Definition eines Betrachterstandpunktes im Raum
    \item Definition einer Projektionsfläche im Raum
    \item Festlegung von Datenstrukturen für alle Objekte
    \item Erstellung eines Algorithmus, der die Szene aus Sicht des Betrachters darstellt, indem
	für jedes Pixel der Projektionsfläche in Abhängigkeit von dem darzustellenden Objekt
	und der Lichtquelle ein Farbwert berechnet wird
    \item Implementation der Datenstrukturen und des Algorithmus in C und OpenGL
    \item Test des implementierten Systems mit verschiedenen Objektkonstellationen und
	Parametereinstellungen
    \item Anfertigung einer Kurzdokumentation
\end{enumerate}
Folgende ergänzende Aufgaben können optional gelöst werden:
\begin{enumerate}
    \item Einbeziehung von gekrümmten Objekten
    \item Verwendung von farbigen Flächen und Lichtquellen
    \item Verwendung von Texturen
    \item Einbeziehung mehrerer Objekte und Lichtquellen
    \item Berechnung von Schatten und Transparenz
    \item Einbeziehung von Reflexionen
    \item Einbeziehung von Refraktionen
    \item Bewegung von Objekten, Lichtquellen oder Betrachter
\end{enumerate}

\subsection{Ergebnis}
Das entwickelte System ist nach Abschluss der Arbeiten im Quelltext bereitzustellen und am
Computer zu demonstrieren.

\section{Erfragte Zusätze}
Folgende zusätzliche Fakten wurden zu dem Beleg erfragt:
\begin{enumerate}
    \item Die Implementierung kann auch in C++ erfolgen.
    \item Das Rendern der Szene muss selbst erfolgen, OpenGL ist lediglich zum 
	Anzeigen des Pixel-Puffers zu verwenden.
    \item Die Wahl des Verfahrens zum Rendern des Bildes ist nicht
	vorgeschrieben, es müssen keine Füll- oder Linienraster-Algorithmen
	implementiert werden.	
\end{enumerate}

\chapter{Umsetzung}
\section{Allgemeines}
Zur Umsetzung der vorliegenden Aufgabe wurde C++ als Programmiersprache gewählt.
Diese hat gegenüber C Verschiedene Vorteile, welche die Implementierung
vereinfachen und den Programmcode robuster machen. Das ist zum Beispiel das
Klassenkonzept, welches es erlaubt, Objekte, wie Dreiecke, Vektoren oder Ebenen
mit den zugehörigen Operationen zu kapseln. Das Konzept der Operatorüberladung
wiederum macht das Arbeiten mit diesen Objekten sehr einfach. So ist eine
Addition der Vektorobjekte $u$ und $v$ einfach als $u + v$ im Code darstellbar.
Des weiteren erlaubt diese Kapselung den einfachen Austausch einzelner
Algorithmen durch effizientere. So ist es problemlos möglich, alle
Vektoroperationen auf die Vektorerweiterungen (z.B. SSE) moderner Prozessoren 
abzubilden und das Programm dadurch zu beschleunigen.

Ein durch dieses Programm fertig beleuchtetes und gerendertes Bild ist im Anhang
als Bild \ref{fig:all} abgebildet.

\section{Szene}
Die Szene wird in der Funktion \texttt{defScene()} der Klasse \texttt{Scene}
definiert. Diese Funktion ist als \texttt{virtual} deklariert. Dies hat den Vorteil, das
bei einer neuen Szene lediglich eine neue Klasse erstellt werden muss, welche
von \texttt{Scene} erbt und die oben genannte Funktion überschreibt.

Die Definition der Szene erfolgt in Polygonen. Polygone können beliebig viele
Ecken (Punkte) haben. Zu beachten ist aber, das Polygone als TriangleStrips implementiert
sind. Das bedeutet, das die ersten drei Punkte zu einem und jeder weitere Punkt 
mit den beiden letzten Punkten zu einem weiterem Dreieck verbunden werden.

Polygone werden durch die Klasse \texttt{Polygon} repräsentiert. Ein Polygon
bekommt bei seiner Initialisierung einen Farbwert sowie einen Licht-Abgabe-Wert.
Die Punkte des Polygons werden als \texttt{Vertex} mit der Funktion
\texttt{addVertex()} zu den momentanem Polygon hinzugefügt. Zuletzt muss das
Polygon mittels \texttt{push\_back()} zu der Liste der Polygone hinzugefügt
werden.

Zu beachten ist, das die ersten drei Punkte des Polygons in Draufsicht gegen den
Uhrzeigersinn festgelegt werden müssen.

Die Dreiecke, welche bei der Definition der Punkte eines Polygons angelegt
werden, werden automatisch in Unterdreiecke einer vorgegebenen Maximalen
Kantenlänge und diese wiederum in Patches einer weiteren vorgegebenen maximalen
Kantenlänge geteilt. Dies geschieht, in dem die längste Kante gesucht und,
falls sie länger als der Schwellwert ist, der Punkt in der Mitte dieser Strecke
($\vec{p}_m$) berechnet wird:
$$\vec{p}_m = \vec{p}_2 + \frac{(\vec{p}_1 - \vec{p}_2)}{2}$$
Anschließend wird die Funktion zum Teilen mit jeweils zwei der Punkte des 
ursprünglichen Dreiecks und dem neuen Punkt aufgerufen erneut aufgerufen. 
Ist der Schwellwert erreicht, so wird das Dreieck in eine Liste hinzugefügt. 
Die Schwellwerte sind in der Datei \texttt{Triangle.cpp} anpassbar (siehe
\ref{fig:patches}).

Dadurch wird eine Hierarchie von Dreiecken erstellt (\texttt{Polygon} 
$\rightarrow$ \texttt{PolygonTriangle} $\rightarrow$ \texttt{PatchTriangle} 
$\rightarrow$ \texttt{Patch}), welche die Anzahl der zu berechnenden und zu
Prüfenden Schnittpunkte wesentlich reduziert. Diese Berechnungen sind sowohl bei
der Sichtbarkeitsberechnung während der Projektion, als auch bei der
Lichtverfolgung während der Beleuchtung erforderlich. Diese Prozesse werden
dadurch wesentlich beschleunigt.

Zu jedem Dreieck (unabhängig von der Hierarchieebene) wird die, durch die drei
Punkte aufgespannte Ebene ($E$) (repräsentiert durch \texttt{Plane})  
mit der zugehörigen Normalen ($\vec{n}$) gebildet:
\begin{eqnarray*}
    E &=& n_1x + n_2y + n_3z + d\\
    \vec{n} &=& (\vec{b} - \vec{a}) \times (\vec{c} - \vec{a})\\
    d &=& -1 * (\vec{n} \cdot \vec{a})
\end{eqnarray*}
Diese werden anschließend zur Schnittpunktberechnung benötigt.

Zudem wird zu jedem \texttt{Polygon}, \texttt{PatchTriangle} sowie
\texttt{Patch} eine das Objekt umgebende Kugel (\texttt{BSphere}) gebildet. Diese wird
benötigt, um den Aufwand bei der Schnittpunktberechnung zu senken, da sich
Schnittpunkte mit Kugeln einfacher berechnen lassen als Schnittpunkte mit
Dreiecken. Eine \texttt{BSphere} besteht nur aus dem Ortsvektor des
Mittelpunktes der Kugel und dem Radius.

Zusätzlich kann die Anzeige eines Polygons beim Renderprozess mittels der
Funktion \texttt{disable()} unterbunden werden. Dies ist nützlich, wenn man die
Beleuchtung eines Raumes mit vier Wänden berechnen will, jedoch zu einer Seite
hineinsehen möchte.

\section{Projektionseinstellungen}
Für die Projektion wird eine Sichtebene definiert. Diese wird durch die Klasse
\texttt{ViewPlane} repräsentiert. Eine Sichtebene (mit der Normale $n$) wird durch 
drei Punkte ($\vec{a}$, $\vec{b}$ und $\vec{c}$) definiert. Diese drei Punkte 
spannen die Ebene auf und bilden zwei Vektoren, welche die Höhe ($h = |\vec{b} - 
\vec{a}|$) und Breite ($b = |\vec{c} - \vec{a}|$) der Ebene definieren (siehe
\ref{fig:view}). Zusätzlich wird der Abstand ($d$) des 
Projektions-Referenzpunkts ($\vec{p}$) angegeben. Dieser Punkt wird als mittig 
hinter der Ebene liegend berechnet:
$$\vec{p} = \vec{a} + \frac{\vec{c} - \vec{a}}{2} + \frac{\vec{b} - \vec{a}}{2}
- d * \frac{\vec{n}}{|\vec{n}|}$$

Zudem wird die Anzahl der Pixel in $x$ und $y$ Richtung übergeben. Anschließend 
werden Faktoren ($s = \frac{h}{y}$, $t = \frac{w}{x}$) gebildet, um jede 
Pixelposition ($\vec{m}$) in dem Sichtfenster durch ein Produkt aus einem Vektor 
und dem Produkt aus Pixeloffset ($\vartriangle x$, $\vartriangle y$) und den 
Faktoren beschreiben zu können:
$$\vec{m} = (\vartriangle x * t * (\vec{c} - \vec{a})) + (\vartriangle y * s * 
(\vec{b} - \vec{a}))$$

Jetzt wird für jedes Pixel ein Vektor vom Projektions-Referenzpunkt durch die
Pixelposition in die Szene gebildet. Aus diesem Vektor wird anschließend eine
Gerade (\texttt{Line}) gebildet ($\vec{p} + u * (\vec{m} - \vec{p})$). Diese
Vektoren werden beim Projektionsprozess benötigt (siehe \ref{sec:proj}).

Die eigentliche Anzeige wird von der Klasse \texttt{View} übernommen, welche
alle Pixeldaten in einem Puffer hält und mit einem mal per 
\texttt{glDrawPixel()} anzeigt.

\section{Beleuchtung (Radiosity)}
\subsection{Generell}
Zur Beleuchtung der Szene wurde das Radiosity-Verfahren implementiert.  Dabei 
wird für je zwei Patchs die Menge der von dem einen auf das
andere Patch abgestrahlte Energie berechnet. Die abgestrahlte Energie des
Patches $j$ ergibt sich dabei aus dem Eigenleuchten plus der reflektierten 
Strahlung und kann mit folgender Gleichung beschrieben werden:
$$B_i = E_i + \rho_i \sum_{j=1}^n B_jF_{ji},\quad 1 \le i \le n$$
Dabei bezeichnet $B_i$ die Gesamtstrahlung des Patches $i$, $B_j$ die des
Patches $j$, $E_i$ das Eigenleuchten des Patches $i$ und $F_{ij}$ den Formfaktor
von $j$ nach $i$. Dieser Formfaktor wird wie folgt berechnet:
$$F_{s,e} = \frac{1}{A_s}\int_{v\in A_e}\int_{u\in A_s} \frac{1}{\pi r^2} 
\cos\phi_u\cos\phi_v V(u,v) \,\mathrm dA_s \mathrm dA_e$$
Wobei $A_{e}$ die Fläche des licht empfangenden und $A_s$ die des sendenden
Patches bezeichnet. Die Winken $\phi_u$ und $\phi_v$ stellen hier die
Schnittwinkel zwischen den Normalen und dem Verbindungsvektor der Patches dar.

Dieses doppelte Integral lässt sich näherungsweise durch die Gleichung:
$$F_{s,e} \approx A_e \frac{\cos\phi_u\cos\phi_v d_{u,v}}{\pi r^2}$$
berechnen. Diese sehr einfache Näherung ist jedoch nur für Patches mit sehr
kleiner Fläche und großer Entfernung korrekt. Daher müssen einige Anpassungen
vorgenommen werden, welche durch den Korrekturfaktor $d_{u,v}$ beschrieben
werden.

Diese Korrektur wird im vorliegendem Programm durch zwei Maßnahmen versucht zu
realisieren. Das erste ist eine Normierung der Summe Aller Formfaktoren zu einem
sendenden Patch auf eins. Dadurch wird sichergestellt, das kein Patch mehr als
seine eigene Energie abgeben kann. Das zweite ist eine Maßnahme, welche das Bild
vor allem in den Ecken verbessert. Es wurde beobachtet (siehe \ref{fig:ff_corner}), 
das Patches, welche direkt orthogonal aneinander grenzen, falsche (zu hohe) 
Formfaktoren und dadurch zu viel Licht aufaddiert bekommen. Daher wird für je
zwei Patches bei der Formfaktorberechnung überprüft, ob der Fall der
orthogonalen Angrenzung zutrifft. Ist dies der Fall, so wird der aktuelle
Formfaktor durch $1,5$ geteilt, ohne die Gesamtsumme zu ändern. Dadurch werden
subjektiv realistischere Bilder generiert (siehe \ref{fig:ff_correct}). 

\subsection{Algorithmus}
Der Algorithmus zur Radiosity-Berechnung ist in der Funktion
\texttt{runLightPass()} der Klasse \texttt{Scene} implementiert. Er iteriert 
zuerst über alle Polygone und für jedes \texttt{Polygon} über alle 
\texttt{PolygonTriangle}s. Für jedes \texttt{PolygonTriangle} wird 
anschließend eine Liste mit den potentiell sichtbaren \texttt{PolygonTriangle}s
erstellt. Dies ist in der Funktion \texttt{findReachables()} implementiert und
prüft lediglich für jedes andere \texttt{PolygonTriangle}, ob alle drei 
Dreieckspunkte hinter der Ebene des Dreiecks liegen. Ist dies der Fall, so ist 
das Dreieck nicht sichtbar und muss nicht beachtet werden.

Anschließend wird über jedes \texttt{Patch} $i$ jedes \texttt{PatchTriangle}s
iteriert. Für jedes \texttt{Patch} wird, wenn die abzugebende Energie des
Patches $i$ größer $0$ ist, die Liste aller Potentiell sichtbaren
Dreiecke durchlaufen und auch hier wieder jedes \texttt{PatchTriangle} und alle
Patches ($j$). 

Für die Patches $i$ und $j$ wird jetzt der Verbindungsvektor \texttt{ray}
gebildet und anschließend die prinzipielle Erreichbarkeit $V$ der Flächen 
über die Lage der Mittelpunkte der Dreiecke zu der Ebene des anderen Dreiecks 
berechnet. Für das Dreieck $i$ und $j$ mit den Mittelpunkten $\vec{m}_{i,j}$ und
den Normalen $\vec{n}_{i,j}$ sehen diese Ausdrücke wie folgt aus:
\begin{eqnarray*}
  V_{ij} &=& (\vec{n}_i * \vec{m}_j * d_i) < 0\\
  V_{ji} &=& (\vec{n}_j * \vec{m}_i * d_j) < 0   
\end{eqnarray*}
Dies entspricht einem Einsetzen der Vektorkomponenten der Mittelpunkte in die
Ebenengleichung der durch die drei Dreieckspunkte des anderen Dreiecks
aufgespannten Ebene.

Wurde eine Prinzipielle Sichtbarkeit festgestellt, so wird die Länge
\texttt{raylen} des Verbindungsvektors und der normierte Verbindungsvektor
berechnet. Anschließend wird die Sichtbarkeit mit der Funktion
\texttt{isReachable()} ermittelt.

In dieser Funktion werden alle \texttt{PolygonTriangle}s, die die Patches $i$
und $j$ nicht enthalten durchgegangen. Für jedes dieser Dreiecke wird getestet,
ob die Verbindungsgerade es schneidet. Dabei werden die Kugeln um die Polygone
genutzt, so kann erst überprüft werden, ob eine teure Schnittpunktberechnung
überhaupt nötig ist. Anschließend wird der Schnittpunkt mit der Dreiecksebene 
berechnet und getestet ob er sich auf dem Verbindungsstück der Gerade liegt. Ist
dies der Fall, so wird getestet, ob sich der Schnittpunkt wirklich in dem
Dreieck befindet. Ist auch das der Fall so wird false (nicht erreichbar)
zurückgegeben. Wird kein Schnittpunkt gefunden der in irgendeinem Dreieck auf
der Verbindungslinie liegt, so wird true (erreichbar) zurück gegeben.

Im Falle der Sichtbarkeit werden die Schnittwinkel $\phi_i$ und $\phi_j$ 
zwischen den normierten Normalen $\vec{n}_i$, $\vec{n}_j$ und dem normiertem
Verbindungsvektor $\vec{v}$ berechnet:
\begin{eqnarray*}
  \cos\phi_i &=& \vec{v} \cdot \vec{n}_i\\
  \cos\phi_j &=& -\vec{v} \cdot \vec{n}_j
\end{eqnarray*}
und die oben genannte Näherungsformel für den Formfaktor ausgerechnet.
Der Formfaktor wird, wenn er größer $0$ ist, zu dem entsprechenden Patch in 
einer Liste gespeichert und zu der Summe der Gesamtformfaktoren addiert.

Zusätzlich wird geprüft, ob für die zwei Patches die oben genannte 
Korrekturmaßnahmne für orthogonal aneinander grenzende Patches gilt. Dazu wird 
zuerst der Winkel zwischen den beiden Normalen der Dreiecksebenen berechnet. 
Wird ein rechter Winkel festgestellt, so wird überprüft, ob die Dreiecke zwei 
Punkte gemeinsam haben. Ist dies der Fall, wird die Maßnahme angewendet.

Anschließend werden alle Formfaktoren so normiert angewendet, das die
Gesamtsumme eins beträgt. Dazu werden die Formfaktoren $F_{ji}$ durch die
Gesamtsumme $S$ geteilt und mit dem Radiosity-Wert $\vartriangle B_i$ aus der
letzten Beleuchtungs-Iteration des Patches $i$ multipliziert. Dieser Wert wird aus der
Summe $\vartriangle B_j$ des Patches $j$ für diese Beleuchtungs-Iteration aufaddiert:
$$\vartriangle{B_j} = \vartriangle{B_j} + \frac{F_{ji}}{S} * \vartriangle B_i$$

Nach einem kompletten wird die Funktion \texttt{updateLight()}
aufgerufen, welche wieder über alle Patches iteriert und die Summen der letzten
Beleuchtungs-Iteration auf die Gesamtsummen anwendet.

Hier kann man erkennen, das während der Beleuchtungsberechnung mehrere
Radiosity-Summen verwendet werden:
\begin{itemize}
  \item Die Summe der Gesamtstrahlung. Sie wird mit der Eigenstrahlung des
    Polygons initialisiert und nach jeder Beleuchtungs-Iteration um die Summe der
    hinzugekommen Strahlung erhöht.
  \item Die Summe der Strahlung aus der letzten Iteration. Sie wird ebenfalls
    mit der Eigenstrahlung initialisiert und bekommt nach jeder Beleuchtungs-Iteration den
    Wert der Summen aus der letzten Beleuchtungs-Iteration zugewiesen.
  \item Die Summe der Strahlung aus der Aktuellen Beleuchtungs-Iteration. Auf diese wird
    während der Beleuchtungs-Iteration die hinzukommende Strahlung aufaddiert. Sie wird zu
    Beginn und nach jeder Beleuchtungs-Iteration mit $0$ initialisiert.
\end{itemize}
Diese Verfahrensweise mit den drei Summen, welche nach den Beleuchtungs-Iterationen
aktualisiert werden wurde als am besten für subjektiv gute Bilder befunden.

Mit Beleuchtungs-Iteration ist ein Durchlauf des kompletten oben beschriebenem Algorithmus
gemeint. Die Anzahl der Durchläufe ist fest in der Funktion \texttt{lighten()} 
festgelegt. Durch hinzufügen von Aufrufen von \texttt{runLightPass()} kann diese
verändert werden (siehe \ref{fig:iter}).

Als Reflektionskonstanten werden die Farbwerte der Dreiecke genutzt. Das
bedeutet, das für jeden Farbkanal unterschiedlich viel Licht reflektiert wird.
Dadurch sind die Radiositywerte der einzelnen Flächen keine skalaren Werte
sondern Farbvektoren, was wieder zur Folge hat, das unterschiedliche Werte für
jeden Farbkanal abgestrahlt und wieder aufgenommen werden, was farbige
Lichtreflektionen verursacht.

Um dies zu vereinfachen ist der Radiositywert, wie die Farben von der Klasse
\texttt{Color}, welche lediglich ein \texttt{Vertex} mit anderem Namen ist, also
ein Vektor. So können Farben die überladenen Operatoren der \texttt{Vertex}-Klasse 
nutzen.

Die Gesamtbeleuchtung der Szene kann durch den Emit-Wert der Licht emittierenden
Flächen eingestellt werden (siehe \ref{fig:light}). Dieser Wert wirkt sich auf
die komplette Szene aus.

\section{Projektion}\label{sec:proj}

Die Projektion der Szene erfolgt nach dem Beleuchten. Als Verfahren zur
Projektion kommt Raycasting zum Einsatz. Das bedeutet, die Szene wird vom
Projektions-Referenzpunkt durch die Sichtebene für jedes Pixel abgerastert. Dazu
werden die oben genannten Geraden durch jedes Pixel der Sichtebene verwendet.

Diese Geraden wurden beim Initialisieren der Sichtebene alle in eine Liste
eingefügt. Diese Liste wird jetzt durchlaufen. Für jede Gerade werden alle
Polygone durchlaufen. Für alle eingeschalteten Polygone wird geprüft, ob die
momentane Gerade die umgebende Kugel schneidet.  Ist dies der Fall, so wird die
Liste aller \texttt{PolygonTriangle}s dieses Polygons durchgegangen und für
jedes der Schnittpunkt mit der durch das Dreieck aufgespannten Ebene gesucht.
Dieser wird, wenn seine Normale in Richtung der Sichtebene zeigt, in eine Liste
angefügt. 

Diese Liste der Schnittpunkte wird nach der Iteration durch die Polygone nach
Abstand zur Sichtebene sortiert.

Danach wird diese Liste durchgegangen und für jeden Schnittpunkt getestet, ob
er in dem entsprechendem Dreieck liegt. Ist dies der Fall, so wird die Liste
nicht weiter durchsucht, da durch die Sortierung dieses ja das Dreieck ist, was
der Sichtebene an dem betrachtetem Punkt am nächsten ist.

Jetzt wird das Patch gesucht, welches der Strahl an diesem Punkt schneidet. Um
den Aufwand zu minimieren wird zuerst nach dem \texttt{PatchTriangle}
gesucht. Auch hier wird wieder Rechenzeit gespart, indem vorerst nur die Kugeln
um die Dreiecke betrachtet werden. Dazu wird jeweils der Abstand zwischen dem
Mittelpunkt der Kugel und dem Schnittpunkt mit der Ebene berechnet. Ist dieser
größer als der Radius der Kugel, so wird das Dreieck nicht weiter betrachtet. 
Andernfalls wird getestet ob der Schnittpunkt auch wirklich in dem momentanem
Dreieck liegt.

Ist dies der Fall, so werden die Patches dieses \texttt{PatchTriangle}s
durchlaufen und genauso wie bei dem \texttt{PatchTriangle} zuerst getestet, ob
der Schnittpunkt in der Kugel liegt und anschließend im Erfolgsfall getestet
ob der Schnittpunkt tatsächlich in dem Dreieck liegt. Ist dies der Fall, so wird
das Pixel an der aktuellen Position mit der Farbe des aktuellen Patches gefüllt.

Dadurch wird das Komplette Bild gerendert. Durch die Sortierung wird immer nur
das Objekt, was an der aktuellen Position der Sichtebene am nächsten ist
gezeichnet. Durch das Bilden der Rastervektoren zwischen dem Referenzpunkt und
der Position auf der Sichtebene entsteht automatisch eine perspektivische
Projektion.

\section{Sonstiges}
\subsection{Schnittpunkt im Dreieck}
Um zu testen ob eine Gerade ein Dreieck schneidet wird zuerst der Schnittpunkt
$\vec{p}$ der Ebene $E$ mit der Normalen $\vec{n}$ und der Ebenengleichung $E =
ax + by + cz + d$, welche die drei Punkte des Dreiecks aufspannen und der Gerade 
$G$ mit der Geradengleichung $\vec{o} + t*\vec{r}$, wobei $\vec{o}$ der 
Ortsvektor und $\vec{r}$ der Richtungsvektor der Geraden ist, berechnet:
\begin{eqnarray*}
    s       &=& -\frac{\vec{n} \cdot \vec{o} + d}{\vec{n} \cdot \vec{d}}\\
    \vec{p} &=& \vec{o} + s * \vec{d}
\end{eqnarray*}
Dabei wird der Nenner der ersten Gleichung $\vec{n} \cdot \vec{d}$ zuerst
ausgewertet. Ist dieser kleiner null kann die Berechnung sofort abgebrochen
werden, da kein Schnittpunkt vorliegt. In diesem Fall liegt die Gerade In der
Ebene oder Parallel dazu.

In jedem anderem Fall wird geprüft, ob der Schnittpunkt in dem Dreieck liegt.
Dazu wird mit der Normalen der Ebene, welche die drei Punkte aufspannen und jeweils
einem der Vektoren zwischen je zwei Punkten eine Weitere Ebene so gebildet,
das die Normale dieser neuen Ebene in das Dreieck zeigt.

Dann muss lediglich der oben berechnete Schnittpunkt $\vec{p}$ in die neue
Ebenengleichung eingesetzt werden:
$$h = p_x a + p_y b + p_z c + d$$
Ist dieser Ausdruck kleiner null, so liegt der Punkt auf der Seite der Ebene,
welche zu dem Dreieck zeigt. Dies muss für alle drei Kanten durchgeführt werden,
wobei beim ersten Misserfolg abgebrochen werden kann.

Ergaben alle drei Prüfungen ein erfolgreiches Ergebnis, so liegt der Punkt in
dem Dreieck. Das bedeutet, das die Gerade das Dreieck schneidet.

\subsection{Schnittpunkt in Kugel}
Um die Anzahl der Schnittpunkttests zwischen Dreiecken und Geraden zu verringern
werden Kugeln um die Dreiecke definiert. So muss nur überprüft werden ob eine
Gerade eine Kugel schneidet oder nicht. Eine Kugel wird durch den Ortsvektor des
Mittelpunktes und den Radius beschrieben. Setzt man die Geradengleichung in die
Kugelgleichung ein, so erhält man eine Quadratische Gleichung für den
Schnittpunkt. Diese lässt sich wie jede andere quadratische Gleichung mit der
Methode:
$$x_{1,2} = \frac{p}{2} \pm \sqrt{\frac{p^2}{4} - q}$$ 
Lösen. In unserem Fall reicht es aber festzustellen, ob ein Schnittpunkt
existiert oder nicht. Dazu muss lediglich der Term unter der Wurzel ausgewertet
werden. Ist dieser kleiner null, so existiert kein Schnittpunkt. Dieser Ausdruck
sieht wie folgt aus:
$$x = \frac{ {2 * \vec{d} \cdot (\vec{o} - \vec{c})}^2 }{4} - {(\vec{o} -
\vec{c})}^2 - r^2$$
Dabei ist $\vec{d}$ der Richtungsvektor und $\vec{o}$ der Ortsvektor der
Geraden. Der Mittelpunkt der Kugel ist $\vec{c}$ und ihr Radius $r$. Die
Variable $x$ ist das auszuwertende Ergebnis.

\begin{appendix}
\chapter{Anhang}
\section{Bilder}
  \begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{img/patches.png}
    \caption{Unterteilung in Patches mit verschiedenen maximalen Kantenlängen.}
    \label{fig:patches}
  \end{figure}
  \begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{img/view.png}
    \caption{Unterschiedliche Lage der Sichtebene.}
    \label{fig:view}
  \end{figure}
  \begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{img/wrong_ff.png}
    \caption{Falsche Formfaktoren in den Ecken.}
    \label{fig:ff_corner}
  \end{figure}
  \begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{img/correct_ff.png}
    \caption{Links: korrigierte Formfaktoren, Rechts: falsche
    Formfaktoren.}
    \label{fig:ff_correct}
  \end{figure}
  \begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{img/iter.png}
    \caption{Scene nach ein, zwei und drei Beleuchtungsiterationen}
    \label{fig:iter}
  \end{figure}
  \begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{img/light.png}
    \caption{Scene mit unterschiedlicher Beleuchtung}
    \label{fig:light}
  \end{figure}
  \begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{img/all.png}
    \caption{Fertig beleuchtetes und gerendertes Bild}
    \label{fig:all}
  \end{figure}
\end{appendix}
\end{document}
